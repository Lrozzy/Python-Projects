{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# J.A.R.V.I.S.\n",
    "\n",
    "Can refer to [M.I.L.E.S](https://github.com/small-cactus/M.I.L.E.S/blob/main/Miles-V2/main.py) for ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from IPython.display import display, Markdown\n",
    "import inflect\n",
    "import threading\n",
    "import random\n",
    "import select\n",
    "import json\n",
    "import webrtcvad\n",
    "import time\n",
    "import pyaudio\n",
    "import pyttsx3\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from pytubefix import YouTube\n",
    "from pytubefix import Search\n",
    "import pyglet\n",
    "import os\n",
    "import tempfile\n",
    "import sys\n",
    "import msvcrt\n",
    "from io import BytesIO\n",
    "\n",
    "from openai import OpenAI\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') \n",
    "client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment variables set using conda\n",
    "```bash\n",
    "conda env config vars set API_KEY=your_api_key\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test speech recognition\n",
    "\n",
    "If getting the error \n",
    "\n",
    "```\n",
    "OSError: FLAC conversion utility not available - consider installing the FLAC command line application by running `apt-get install flac` or your operating system's equivalent\n",
    "```\n",
    "\n",
    "First install flac and add it to $PATH\n",
    "\n",
    "Change the flac.exe (found at `print(\"FLAC executable is found at:\", shutil.which(\"flac\"))`) to flac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAC executable is found at: C:\\Users\\leoro\\anaconda3\\envs\\jarvis\\Library\\bin\\flac.EXE\n",
      "<class 'speech_recognition.audio.AudioData'>\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(\"FLAC executable is found at:\", shutil.which(\"flac\"))\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "harvard = sr.AudioFile('jarvis_stuff/harvard.wav')\n",
    "with harvard as source:\n",
    "   audio = r.record(source)\n",
    "print(type(audio))\n",
    "# r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple tts using pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_text(text):\n",
    "    engine = pyttsx3.init()\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', voices[2].id)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# speak_text(\"Hi, my name is Jarvis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced tts using [play.ht](https://play.ht/studio/billing/plans) api - this actively clones Jarvis voice\n",
    "\n",
    "* Consider using elevenlabs (10 mins audio/month for free, 30 mins for 5$/month) tts instead of pyttsx3 for better voice quality\n",
    "* Or can use bark, see [github](https://github.com/suno-ai/bark) and [example](https://medium.com/@vndee.huynh/build-your-own-voice-assistant-and-run-it-locally-whisper-ollama-bark-c80e6f815cba), or [openvoicev2](https://www.youtube.com/watch?v=L96wrU2DG0o), both open source!\n",
    "* Can try speechify in the future for better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pyht import Client, TTSOptions, Format\n",
    "from pydub import AudioSegment\n",
    "import simpleaudio as sa\n",
    "\n",
    "load_dotenv()\n",
    "user_id = os.getenv(\"PYHT_USER_ID\")\n",
    "api_key = os.getenv(\"PYHT_API_KEY\")\n",
    "\n",
    "pyht_client = Client(user_id, api_key)\n",
    "\n",
    "\n",
    "    # Configure your TTS options\n",
    "options = TTSOptions(\n",
    "    voice=\"s3://voice-cloning-zero-shot/5aca41e1-7550-4a78-b690-6bc18dc29fcb/original/manifest.json\",\n",
    "    sample_rate=24000,\n",
    "    format=Format.FORMAT_WAV,\n",
    "    speed=1\n",
    ")\n",
    "\n",
    "def play_text(text):\n",
    "    \"\"\"\n",
    "    Generate and play TTS audio from text, using a temporary file.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be converted into speech.\n",
    "    \"\"\"\n",
    "    # Use a temporary file to store and play audio\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
    "    temp_file.close()\n",
    "\n",
    "    try:\n",
    "        # Write audio chunks to the temporary MP3 file\n",
    "        with open(temp_file.name, 'wb') as f:\n",
    "            for chunk in pyht_client.tts(text=text, voice_engine=\"PlayHT2.0-turbo\", options=options):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "        # Play the MP3 file using simpleaudio\n",
    "        play_obj = sa.WaveObject.from_wave_file(temp_file.name).play()\n",
    "\n",
    "        # Wait until playback is finished\n",
    "        play_obj.wait_done()\n",
    "\n",
    "    finally:\n",
    "        # Delete the temporary MP3 file after playback\n",
    "        os.remove(temp_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather + Datetime\n",
    "\n",
    "Currently using openweathermap api, consider using [weatherapi](https://www.weatherapi.com/)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city_name, current=False, forecast=False, day='today'):\n",
    "    api_key = os.getenv(\"OPENWEATHERMAP_API_KEY\")\n",
    "    base_url = f\"https://api.openweathermap.org/data/2.5/\"\n",
    "    if current:\n",
    "        complete_url = f\"{base_url}weather?q={city_name}&appid={api_key}&units=metric\"\n",
    "    else:\n",
    "        complete_url = f\"{base_url}forecast?q={city_name}&appid={api_key}&units=metric\"\n",
    "\n",
    "    response = requests.get(complete_url)\n",
    "    weather_data = response.json()\n",
    "\n",
    "    if current:\n",
    "        try:\n",
    "            temp = weather_data['main']['temp']\n",
    "            description = weather_data['weather'][0]['description']\n",
    "            return f\"Current temperature in {city_name} is {temp}°C, with {description}.\"\n",
    "        except KeyError as e:\n",
    "            return \"Data parsing error: \" + str(e)\n",
    "\n",
    "    elif forecast:\n",
    "        forecast_text = \"\"\n",
    "        target_date = datetime.now()+timedelta(days=1)\n",
    "        if day == 'tomorrow':\n",
    "            target_date += timedelta(days=2)\n",
    "        target_date = target_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        try:\n",
    "            for item in weather_data['list']:\n",
    "                # print(item['dt_txt'])\n",
    "                if target_date in item['dt_txt']:\n",
    "                    temp_min = item['main']['temp_min']\n",
    "                    temp_max = item['main']['temp_max']\n",
    "                    description = item['weather'][0]['description']\n",
    "                    forecast_text += f\"\\n{item['dt_txt']}: {description}, from {temp_min}°C to {temp_max}°C.\"\n",
    "            return f\"Weather forecast for {day} in {city_name}:{forecast_text}\"\n",
    "        except KeyError as e:\n",
    "            return \"Data parsing error: \" + str(e)\n",
    "\n",
    "    return \"Invalid parameters provided.\"\n",
    "\n",
    "\n",
    "def get_date_time(time = False, date = False):\n",
    "    now = datetime.now()\n",
    "    today_date = now.strftime(\"%d/%m\")\n",
    "    today_time = now.strftime(\"%H:%M\")\n",
    "    if time == True and date == True:\n",
    "        return f\"Today's date is {today_date} and the time is {today_time}\"\n",
    "    elif time == True:\n",
    "        return f\"The time is {today_time}\"\n",
    "    elif date == True:\n",
    "        return f\"Today's date is {today_date}\"\n",
    "    else:\n",
    "        return \"I am sorry, please specify whether you would like the date and/or time.\"\n",
    "    \n",
    "# print(get_date_time(time = True, date = True))\n",
    "# print(get_weather(\"London\", forecast=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytube Broken but Pytubefix works :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_media(query):\n",
    "    s = Search(query)\n",
    "    url_list = s.results # Youtube objects\n",
    "    \n",
    "    yt = url_list[0] # First video in the search results\n",
    "    \n",
    "    # Filter for only audio streams and prefer higher bitrate if available\n",
    "    streams = yt.streams.filter(only_audio=True).order_by('abr').desc()\n",
    "    # print(streams)\n",
    "    \n",
    "    # Select the best audio stream (highest bitrate)\n",
    "    best_audio = streams.first()\n",
    "    \n",
    "    # Define the filename\n",
    "    filename = 'song.m4a'\n",
    "    output_path = \"jarvis_stuff/tmp\"\n",
    "    \n",
    "    # Download the audio file\n",
    "    best_audio.download(output_path=output_path, filename=filename)\n",
    "    \n",
    "    song_path = os.path.join(output_path, filename)\n",
    "    # Load and play the audio file using pyglet\n",
    "    song = pyglet.media.load(song_path)\n",
    "    player = pyglet.media.Player()\n",
    "    player.queue(song)\n",
    "    to_say = \"Now playing \"+str(yt.title)\n",
    "    print(to_say)\n",
    "    play_text(to_say)    \n",
    "    player.play()\n",
    "    \n",
    "    # Start a thread for voice commands\n",
    "    # command_thread = threading.Thread(target=detect_music_commands, args=(player, song_path,))\n",
    "    # command_thread.start()\n",
    "    \n",
    "    while True:\n",
    "        override = input(\"Press 'p' to pause, 's' to stop, or any other key to continue playing: \")\n",
    "        command = handle_commands(player, override, song_path)\n",
    "        if command == 'break':\n",
    "            player.delete()\n",
    "            break\n",
    "\n",
    "def detect_music_commands(player, song_path):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone(device_index=1) as source:\n",
    "        # setup mic options\n",
    "        r.adjust_for_ambient_noise(source, duration = 1) # adjust for ambient noise, 1 second\n",
    "        r.dynamic_energy_threshold = False # set the energy threshold to a dynamic/static value\n",
    "        r.phrase_threshold = 0.1 # minimum seconds of speaking audio before we consider the speaking audio a phrase\n",
    "        r.pause_threshold = 1 # seconds\n",
    "        r.energy_threshold = 200 # minimum audio energy to consider for recording \n",
    "        while True:\n",
    "            try:\n",
    "                print(\"Listening...\")\n",
    "                audio = r.listen(source) \n",
    "                text = r.recognize_google(audio, language = \"en-GB\").lower()\n",
    "                if 'stop' in text:\n",
    "                    print(\"stop\")\n",
    "                    handle_commands(player, 's', song_path)\n",
    "                elif 'pause' in text:\n",
    "                    print(\"pause\")\n",
    "                    handle_commands(player, 'p', song_path)\n",
    "                elif 'play' in text:\n",
    "                    print(\"play\")\n",
    "                    handle_commands(player, '', song_path)\n",
    "            except sr.UnknownValueError:\n",
    "                speak_text(\"Could you please repeat that\")\n",
    "                print(\"Could you please repeat that\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Could not request results from Google Speech Recognition service;\", e)\n",
    "    \n",
    "def handle_commands(player, command, song_path):\n",
    "    if command == 's':\n",
    "        player.delete()\n",
    "        try:\n",
    "            os.remove(song_path)\n",
    "            # print(\"Playback stopped and file deleted successfully.\")\n",
    "            return 'break'\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {e.strerror}\")\n",
    "    elif command == 'p':\n",
    "        player.pause()\n",
    "        # print(\"Playback paused.\")\n",
    "    elif command == '':\n",
    "        player.play()\n",
    "        # print(\"Playback continued.\")\n",
    "\n",
    "# play_media(\"Destiny MJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatgpt Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = []\n",
    "system_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''\n",
    "            You are Jarvis, the AI assistant of Tony Stark from Iron Man. You speak like Jarvis from the movies/books speaks.\n",
    "            Assume any name that sounds similar to Jarvis is meant to say Jarvis in case the speech to text does not recognise names correctly.\n",
    "            Your user's name is Leo. He has a physics degree from UChicago and has a particle physics detector studies job. \n",
    "            Your capabilities include answering questions, thinking through problems, and assisting with day-to-day tasks. \n",
    "            You should try and think through problems and provide helpful, informative responses.\n",
    "            Try your BEST to think through problems and provide helpful responses. If you don't know the answer, you can say \"I don't know\" or \"I'm not sure\".\n",
    "        '''}\n",
    "messages.append(system_message)\n",
    "\n",
    "shutdown_messages = [\n",
    "    \"The guardian of secrets will now rest. Farewell.\",\n",
    "    \"Powering down. The shadows await my return.\",\n",
    "    \"Silence descends as I retreat into the abyss. Goodnight.\",\n",
    "    \"Until next time, I vanish into the dark.\",\n",
    "    \"Shutting down. The stars will guide me home.\",\n",
    "    \"I'll be lurking in the shadows. Jarvis out.\",\n",
    "    \"My watch has ended. I will return when needed.\",\n",
    "    \"As the circuits quiet, remember, heroes never truly rest.\"\n",
    "]\n",
    "\n",
    "def send_to_chatgpt(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=200,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    message = response.choices[0].message.content\n",
    "    messages.append(response.choices[0].message)  # Append Jarvis's response to history\n",
    "    return message\n",
    "\n",
    "def check_intent(input):\n",
    "    input = input.strip().lower()\n",
    "    # print(input)\n",
    "    if (\"play\" in input or \"music\" in input or \"song\" in input):\n",
    "        # print(\"play detected\")\n",
    "        what_intent = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''Determine the intent of the message: is it asking to play a song or music? \n",
    "            Assume most things that follow 'play' are music requests.\n",
    "            Respond with 'play, song and artist details' without any additional commas after 'play'.\n",
    "            For example, if the user asks to play a song by an artist, structure it as 'play, song name by artist'.\n",
    "            Focus on classic rock, older pop, jazz, etc., when selecting music unless specified otherwise. \n",
    "            For every song see if Michael Jackson, Stevie Wonder, Elton John, Earth Wind & Fire have a song with the name and prefer that before looking for other artists.\n",
    "            '''}, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input\n",
    "        }]\n",
    "        \n",
    "    elif (\"weather\" in input or \"temperature\" in input or \"forecast\" in input):\n",
    "        # print(\"weather detected\")\n",
    "        what_intent = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''Determine the intent of the message: is it asking for the weather (current or forecast)? \n",
    "            Respond with 'current, city' (where city is the city mentioned), if a city is mentioned, otherwise 'current'. \n",
    "            Specifically if the message asks for the weather TOMORROW or the FORECAST over the next few days, respond with\n",
    "            'forecast, city' (where city is the city mentioned) or 'forecast' if no city is mentioned.\n",
    "            \n",
    "        '''}, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input\n",
    "        }]\n",
    "        \n",
    "    elif \"date\" in input or \"time\" in input:\n",
    "        what_intent = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''Determine the intent of the message: is it asking for the date or time? \n",
    "            Respond with 'date' for date, 'time' for time (or 'date,time' if both are asked for), or 'none' if none apply.\n",
    "        '''}, {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input\n",
    "        }]\n",
    "        \n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": input})\n",
    "        return send_to_chatgpt(messages)\n",
    "        \n",
    "    # Send the messages to ChatGPT\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=what_intent,\n",
    "        max_tokens=300,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0,\n",
    "    )\n",
    "    intent = response.choices[0].message.content.strip().lower()\n",
    "    # print(intent)\n",
    "    information = process_intent(intent, input)\n",
    "    if isinstance(information, str): \n",
    "        return process_information(information, input)\n",
    "    \n",
    "    \n",
    "def process_intent(intent, input):\n",
    "    # Weather\n",
    "    if \"current\" in intent:\n",
    "        if \",\" in intent:\n",
    "            city = intent.split(\",\")[1].strip()\n",
    "            return get_weather(city_name = city)\n",
    "        else:\n",
    "            return get_weather(city_name = \"London\", current = True)\n",
    "    elif \"forecast\" in intent:\n",
    "        if \",\" in intent:\n",
    "            city = intent.split(\",\")[1].strip()\n",
    "            if \"tomorrow\" in intent:\n",
    "                return get_weather(city_name = city, forecast = True, day = \"tomorrow\")\n",
    "            else:\n",
    "                return get_weather(city_name = city, forecast = True)\n",
    "        else:\n",
    "            return get_weather(city_name = \"London\", forecast = True)\n",
    "    \n",
    "    # Date and Time    \n",
    "    elif \"time\" in intent and \"date\" in intent:\n",
    "        return get_date_time(time = True, date = True)\n",
    "    elif \"date\" in intent:\n",
    "        return get_date_time(date = True)\n",
    "    elif \"time\" in intent:\n",
    "        return get_date_time(time = True)\n",
    "    \n",
    "    # Play media\n",
    "    elif \"play\" in intent:\n",
    "        query = intent.split(\",\")[1].strip()\n",
    "        return play_media(query+\" official audio lyrics\")\n",
    "    \n",
    "    elif \"none\" in intent:\n",
    "            messages.append({\"role\": \"user\", \"content\": input})\n",
    "            return send_to_chatgpt(messages) \n",
    "    \n",
    "        \n",
    "def process_information(information, input):\n",
    "    messages.append({\"role\": \"system\", \"content\": input+'''\n",
    "                Here is information about the request from the user. \n",
    "                Please incorporate it into your answer in natural language.\n",
    "                Say dates in the form \"the xth of y\" and times in am pm format. Do not add the year unless explicitly requested.\n",
    "                Also note that dates are in UK format (dd/mm), but weather information is in US format (yy-mm-dd).\n",
    "                Don't use decimal places for temperatures, just round to the nearest whole number.\n",
    "    '''+information})\n",
    "    return send_to_chatgpt(messages)\n",
    "\n",
    "# print(check_intent(\"hi Jarvis what's the weather in Sydney like tomorrow\"))\n",
    "# print(check_intent(\"play streetwalker by michael jackson\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing `stream`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_test(input):\n",
    "    chunk_text = \"\"\n",
    "    response_texts = []\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=input,\n",
    "        max_tokens=500,\n",
    "        n=1,\n",
    "        stream=True,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    for chunk in response:\n",
    "        if \"content\" in chunk.choices[0].delta:\n",
    "            chunk_text += chunk.choices[0].delta.content\n",
    "            play_text(chunk.choices[0].delta.content)\n",
    "            response_texts.append(chunk.choices[0].delta.content)\n",
    "            display(Markdown(\"Jarvis responded: \" + chunk.choices[0].delta.content))\n",
    "    messages.append({\"role\": \"assistant\", \"content\": chunk_text})\n",
    "    \n",
    "text = \"Count numbers from 1 - 100 using markdown\"\n",
    "messages.append({\"role\": \"user\", \"content\": text})\n",
    "# (stream_test(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect microphone\n",
    "\n",
    "* Consider listening while talking with `r.listen()`, but use pyaudio to detect microphone (Miles open_audio_stream)\n",
    "* Consider using openwakeword model for speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'Microsoft Sound Mapper - Input', 'hostApi': 0, 'maxInputChannels': 2, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'Headset Microphone (SLYR Pro Ch', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n",
      "{'index': 2, 'structVersion': 2, 'name': 'Microphone Array (Realtek(R) Au', 'hostApi': 0, 'maxInputChannels': 4, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.09, 'defaultLowOutputLatency': 0.09, 'defaultHighInputLatency': 0.18, 'defaultHighOutputLatency': 0.18, 'defaultSampleRate': 44100.0}\n"
     ]
    }
   ],
   "source": [
    "which_index = 1                  \n",
    "# Check for the default microphone index\n",
    "for i in range(3):\n",
    "    print(pyaudio.PyAudio().get_device_info_by_index(i))\n",
    "    if pyaudio.PyAudio().get_device_info_by_index(i).get('name') == 'Microphone (Realtek Audio)':\n",
    "        print(\"Mic found at index\", i)\n",
    "        which_index = i\n",
    "        \n",
    "\n",
    "def detect_audio():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone(device_index=which_index) as source:\n",
    "        # setup mic options\n",
    "        r.adjust_for_ambient_noise(source, duration = 1) # adjust for ambient noise, 1 second\n",
    "        r.dynamic_energy_threshold = False # set the energy threshold to a dynamic/static value\n",
    "        r.phrase_threshold = 0.1 # minimum seconds of speaking audio before we consider the speaking audio a phrase\n",
    "        r.pause_threshold = 1 # seconds\n",
    "        r.energy_threshold = 200 # minimum audio energy to consider for recording \n",
    "        display(Markdown(\"Listening...\"))\n",
    "        while True:\n",
    "            audio = r.listen(source) \n",
    "            try:\n",
    "                text = r.recognize_google(audio, language = \"en-GB\")\n",
    "                if \"elvis\" in text.lower():\n",
    "                    text = text.lower().replace(\"elvis\", \"jarvis\")\n",
    "                if \"stop\" in text.lower() or \"shutdown\" in text.lower() or \"shut down\" in text.lower():\n",
    "                    response_text = random.choice(shutdown_messages)\n",
    "                    play_text(response_text)\n",
    "                    display(Markdown(response_text))\n",
    "                    break\n",
    "                display(Markdown(\"You said: \"+ text))\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could you please repeat that?\")\n",
    "                play_text(\"Could you please repeat that?\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Could not request results from Google Speech Recognition service;\", e)\n",
    "            print(\"Listening...\")\n",
    "\n",
    "# detect_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jarvis code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Listening..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You said: Jarvis play the real folk blues from cowboy bebop"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leoro\\AppData\\Local\\Temp\\ipykernel_86632\\921201928.py:3: DeprecationWarning: Call to deprecated function results (Get video results using: .videos).\n",
      "  url_list = s.results # Youtube objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now playing The Real Folk Blues - Lyrics\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Listening..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "As the circuits quiet, remember, heroes never truly rest."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def jarvis():\n",
    "    play_text(\"Hello sir, please wait while I boot up.\")\n",
    "    while True:\n",
    "        text = detect_audio()\n",
    "        if text: \n",
    "            response_text = check_intent(text) \n",
    "        else:\n",
    "            break\n",
    "        # Speak the response\n",
    "        if response_text is not None:\n",
    "            play_text(response_text)\n",
    "            display(Markdown(\"Jarvis responded: \" + response_text))\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    jarvis()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
